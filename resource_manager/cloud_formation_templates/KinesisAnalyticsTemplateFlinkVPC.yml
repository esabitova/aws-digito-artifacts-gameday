#
# Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this
# software and associated documentation files (the "Software"), to deal in the Software
# without restriction, including without limitation the rights to use, copy, modify,
# merge, publish, distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
# PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#
---
AWSTemplateFormatVersion: 2010-09-09
Description: "Sample KinesisDataAnalytics via CloudFormation"
Outputs:
  KinesisAnalyticsApplicationPhysicalResourceId:
    Description: Export application ApplicationPhysicalResourceId for outward reference
    Value: !Ref KinesisAnalyticsFlinkApplication
  InputKinesisAnalyticsStreamName:
    Description: Name of input stream, to populate with stream data
    Value: !Ref InputKinesisStream
  OutputKinesisAnalyticsStreamName:
    Description: Name of output stream, to extract processed stream data
    Value: !Ref OutputKinesisStream
  KinesisDataAnalyticsSecurityGroupsIdList:
    Description: The list of kinesis data analytics security groups id, which allows to interact with VPC resources
    Value: !Ref KDASecurityGroupId
  DynamoDbOutputId:
    Description: The ID of DynamoDb table, which collects output of Kinesis Data Analytics application
    Value: !Ref DynamoDBOutputTable
  InputStreamLambdaLoaderName:
    Description: The ID of Input stream lambda loader
    Value: !Ref InputStreamLambdaLoader
Parameters:
  S3FlinkCodeBucket:
    Type: String
    Description: S3 bucket with Kinesis Data Analytics for Apache Flink application python code import parameter
    Default: ""
  FlinkApplicationObjectKey:
    Type: String
    Description: Object key in s3 bucket for Apache Flink application file
    Default: ""
  KmsKey:
    Type: String
    Description: KMS encryption Key Arn
    Default: ""
  VPC:
    Description: VPC id
    Type: String
  PrivateSubnetKDA:
    Type: String
    Description: Private subnet for Kinesis Data Analytics application
  SubnetCidr:
    Description: IP range in CIDR notation for the VPC
    Type: String
    Default: 10.0.0.0/22
Resources:
  KinesisStreamEndpoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal: 
              AWS: 
                - !Sub "${AWS::AccountId}"
            Action:
              - kinesis:DescribeStream
              - kinesis:GetShardIterator
              - kinesis:GetRecords
              - kinesis:GetShardIterator
              - kinesis:ListShards
              - kinesis:DescribeStreamSummary
              - kinesis:DescribeStreamConsumer
              - kinesis:SubscribeToShard
              - kinesis:RegisterStreamConsumer
              - kinesis:PutRecord
              - kinesis:PutRecords
              - kinesis:ListStreams                               
            Resource: 
              - !GetAtt 'OutputKinesisStream.Arn'
              - !GetAtt 'InputKinesisStream.Arn'
          - Effect: Allow
            Principal: 
              AWS: 
                - !Sub "${AWS::AccountId}"
            Action:
              - kms:Encrypt
              - kms:Decrypt
              - kms:ReEncrypt
              - kms:GenerateDataKey
              - kms:DescribeKey
            Resource: !Sub '${KmsKey}'
      PrivateDnsEnabled: true
      SecurityGroupIds:
        - !Ref StreamVpcEndpointSecurityGroup
      ServiceName: !Sub 'com.amazonaws.${AWS::Region}.kinesis-streams'
      SubnetIds: 
        - !Sub '${PrivateSubnetKDA}'
      VpcEndpointType: Interface
      VpcId: !Sub '${VPC}'  
  StreamVpcEndpointSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: "Kinesis Streams VPC Endpoint security group"
      VpcId: !Sub '${VPC}'
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: !Sub '${SubnetCidr}'
      SecurityGroupEgress: 
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: !Sub '${SubnetCidr}'
  KDASecurityGroupId:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Kinesis Data Analytics application security group
      VpcId: !Sub '${VPC}'
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: !Sub '${SubnetCidr}'
      SecurityGroupEgress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: !Sub '${SubnetCidr}'
  LambdaSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Input stream loader lambda security group
      VpcId: !Sub '${VPC}'
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: !Sub '${SubnetCidr}'
      SecurityGroupEgress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: !Sub '${SubnetCidr}'
  DynamoDBOutputTable:
    Type: AWS::DynamoDB::Table
    Properties:
      BillingMode: PAY_PER_REQUEST
      AttributeDefinitions:
        - AttributeName: TABLEKEY
          AttributeType: "S"
        - AttributeName: TICKER
          AttributeType: "S" 
      KeySchema:
        - AttributeName: TABLEKEY
          KeyType: HASH
      GlobalSecondaryIndexes:
        - IndexName: TICKER
          KeySchema:
            - AttributeName: TICKER
              KeyType: HASH
          Projection:
            ProjectionType: ALL
      PointInTimeRecoverySpecification:
        PointInTimeRecoveryEnabled: true
      SSESpecification:
        KMSMasterKeyId: !Sub '${KmsKey}'
        SSEEnabled: true
        SSEType: KMS
  InputStreamLambdaLoader:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          """generates dummy data to input stream """
          import json
          import os
          import random
          import time
          from os import getenv
          from datetime import datetime, timedelta
          import boto3
          def handler(event, context):
            input_stream = getenv('InputStreamName')
            kinesis_client = boto3.client('kinesis')
            data = {'event_time': datetime.utcnow().isoformat(),
                    'ticker': random.choice(['AAPL', 'AMZN', 'MSFT', 'INTC', 'TBV']),
                    'price': round(random.random() * 100, 2)}
            kinesis_client.put_record(
                StreamName=input_stream,
                Data=json.dumps(data),
                PartitionKey="partitionkey")
            time.sleep(1)
            return {"statusCode": 200, "body": json.dumps(data)}            
      Description: Dummy ticker data to load to InputStream
      Handler: index.handler
      Role: !GetAtt 'OutputProcessingLambdaRole.Arn'
      Environment:
        Variables:
          InputStreamName:
            !Ref InputKinesisStream
      Runtime: python3.8
      Timeout: 900
      ReservedConcurrentExecutions: 10
      VpcConfig:
        SubnetIds:
          - !Sub "${PrivateSubnetKDA}"
        SecurityGroupIds:
          - !Ref LambdaSecurityGroup
  OutputLambdaProcessor:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          """fanout.py reads from kinesis data analytic output and fans out to DynamoDB"""            
          import base64
          import json
          import os
          from os import getenv
          from datetime import datetime
          import boto3
          ddb = boto3.resource("dynamodb")
          def handler(event, context):
            for record in event['Records']:
              payload = base64.b64decode(record['kinesis']["data"])
              data = json.loads(payload.decode())
              tablekey = record['kinesis']['sequenceNumber']
              dynamodb_table_name = getenv('DbName')
              table = ddb.Table(dynamodb_table_name)
              item = {
                "TABLEKEY": tablekey,
                "TICKER": data['ticker'],
                "PRICE": str(data['price']),
                "EVENT_TIME": data['event_time']
              }
              table.put_item(
                Item=item,
                ConditionExpression="attribute_not_exists(inspectedAt)")
            return {"statusCode": 200, "body": json.dumps(item)}            
      Description: Dummy OutputStream processing lambda function
      Handler: index.handler
      Role: !GetAtt 'OutputProcessingLambdaRole.Arn'
      Environment:
        Variables:
          DbArn:
            !GetAtt DynamoDBOutputTable.Arn
          DbName:
            !Ref DynamoDBOutputTable
      Runtime: python3.8
      Timeout: 900
      ReservedConcurrentExecutions: 10
  LambdaEventSource: 
    Type: AWS::Lambda::EventSourceMapping
    Properties: 
      EventSourceArn: !GetAtt 'OutputKinesisStream.Arn'
      FunctionName: !GetAtt 'OutputLambdaProcessor.Arn'
      StartingPosition: "LATEST" 
  KinesisAnalyticsFlinkApplication:
    Type: AWS::KinesisAnalyticsV2::Application
    Properties:
      RuntimeEnvironment: FLINK-1_11
      ServiceExecutionRole: !GetAtt KinesisAnalyticsRole.Arn
      ApplicationConfiguration:
        ApplicationCodeConfiguration:
          CodeContent:
            S3ContentLocation:
              BucketARN: !Sub "arn:aws:s3:::${S3FlinkCodeBucket}"
              FileKey: !Sub "${FlinkApplicationObjectKey}"
          CodeContentType: ZIPFILE
        EnvironmentProperties:
          PropertyGroups:
            - PropertyGroupId: kinesis.analytics.flink.run.options
              PropertyMap:
                python: !Join ["/", [!Select [1, !Split ["/", !Select [0, !Split [".", !Sub "${FlinkApplicationObjectKey}"]]]], "main.py"]]
                jarfile: !Join ["/", [!Select [1, !Split ["/", !Select [0, !Split [".", !Sub "${FlinkApplicationObjectKey}"]]]], "lib", "amazon-kinesis-sql-connector-flink-2.0.3.jar"]]
            - PropertyGroupId: producer.config.0
              PropertyMap:
                output.stream.name: !Ref OutputKinesisStream
                aws.region: !Sub "${AWS::Region}"
                shard.count: "1"
            - PropertyGroupId: consumer.config.0
              PropertyMap:
                input.stream.name: !Ref InputKinesisStream
                aws.region: !Sub "${AWS::Region}"
                flink.stream.initpos: "LATEST"
        ApplicationSnapshotConfiguration:
          SnapshotsEnabled: false
        FlinkApplicationConfiguration:
          CheckpointConfiguration:
            ConfigurationType: CUSTOM
            CheckpointingEnabled: true
            CheckpointInterval: 60000
            MinPauseBetweenCheckpoints: 5000
          ParallelismConfiguration:
            ConfigurationType: CUSTOM
            AutoScalingEnabled: true
            Parallelism: 1
            ParallelismPerKPU: 2  
  OutputProcessingLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Description: Lambda Role
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: !Join
            - "-"
            - - "policy-digito-output-stream-process-lambda"
              - !Select
                - 0
                - !Split
                  - "-"
                  - !Select
                    - 2
                    - !Split
                      - "/"
                      - !Ref "AWS::StackId"
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Sid: getkinanaccess
                Effect: Allow
                Action:
                  - kinesis:DescribeStream
                  - kinesis:GetShardIterator
                  - kinesis:GetRecords
                  - kinesis:GetShardIterator
                  - kinesis:ListShards
                  - kinesis:DescribeStreamSummary
                  - kinesis:DescribeStreamConsumer
                  - kinesis:SubscribeToShard
                  - kinesis:RegisterStreamConsumer
                  - kinesis:PutRecord
                  - kinesis:PutRecords
                  - kinesis:ListStreams                  
                Resource: 
                  - !GetAtt 'OutputKinesisStream.Arn'
                  - !GetAtt 'InputKinesisStream.Arn'
              - Sid: usekmskeybyoutputlambda
                Effect: Allow
                Action:
                  - kms:Encrypt
                  - kms:Decrypt
                  - kms:ReEncrypt*
                  - kms:GenerateDataKey*
                  - kms:DescribeKey
                Resource: !Sub '${KmsKey}'
              - Sid: puttodynamodb
                Effect: Allow
                Action:
                  - dynamodb:BatchGetItem
                  - dynamodb:GetItem
                  - dynamodb:Scan
                  - dynamodb:Query
                  - dynamodb:BatchWriteItem
                  - dynamodb:PutItem
                  - dynamodb:UpdateItem
                Resource: !GetAtt 'DynamoDBOutputTable.Arn'
              - Sid: cwatchoutput
                Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - logs:GetLogEvents
                  - logs:DescribeLogStreams
                  - logs:PutDestination
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
  KinesisAnalyticsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: kinesisanalytics.amazonaws.com
            Action: "sts:AssumeRole"      
      Path: "/"
      Policies:        
        - PolicyName: !Join
            - "-"
            - - "policy-digito-kinesis-application"
              - !Select
                - 0
                - !Split
                  - "-"
                  - !Select
                    - 2
                    - !Split
                      - "/"
                      - !Ref "AWS::StackId"
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Sid: readcode 
                Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:GetObjectVersion
                Resource:
                  - !Sub "arn:aws:s3:::${S3FlinkCodeBucket}"
                  - !Join ['/' , [!Sub "arn:aws:s3:::${S3FlinkCodeBucket}", !Sub "${FlinkApplicationObjectKey}"]]
              - Sid: cloudwatchmetricdata   
                Effect: Allow
                Action:
                  - cloudwatch:*
                  - logs:*
                Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/kinesis-analytics/*"
              - Sid: kinesisdatastreamsactivity
                Effect: Allow
                Action:
                  - kinesis:DescribeStream
                  - kinesis:GetShardIterator
                  - kinesis:GetRecords
                  - kinesis:GetShardIterator
                  - kinesis:ListShards
                  - kinesis:DescribeStreamSummary
                  - kinesis:DescribeStreamConsumer
                  - kinesis:SubscribeToShard
                  - kinesis:RegisterStreamConsumer
                  - kinesis:PutRecord
                  - kinesis:PutRecords
                  - kinesis:ListStreams                
                Resource:
                  - !GetAtt 'InputKinesisStream.Arn'
                  - !GetAtt 'OutputKinesisStream.Arn'
              - Sid: kinesisdataanalyticsapp  
                Effect: Allow
                Action:
                  - kms:Encrypt
                  - kms:Decrypt
                  - kms:ReEncrypt
                  - kms:GenerateDataKey
                  - kms:DescribeKey
                Resource: !Sub '${KmsKey}'
              - Sid: VPCReadOnlyPermissions
                Effect: Allow
                Action:
                  - ec2:DescribeVpcs
                  - ec2:DescribeSubnets
                  - ec2:DescribeSecurityGroups
                  - ec2:DescribeDhcpOptions
                  - ec2:DescribeNetworkInterfaces
                Resource: "*"
              - Sid: ENIReadWritePermissions
                Effect: Allow
                Action:
                  - ec2:CreateNetworkInterface
                  - ec2:CreateNetworkInterfacePermission                  
                  - ec2:DeleteNetworkInterface
                Resource: "*"
  InputKinesisStream:
    Type: AWS::Kinesis::Stream
    Properties:
      ShardCount: 1
      StreamEncryption:
        EncryptionType: KMS
        KeyId: !Sub '${KmsKey}'
  OutputKinesisStream:
    Type: AWS::Kinesis::Stream
    Properties:
      ShardCount: 1
      StreamEncryption:
        EncryptionType: KMS
        KeyId: !Sub '${KmsKey}'
